{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Roberta.ipynb",
      "provenance": [],
      "mount_file_id": "1kB0JCWpeUvwRu9NBueyjBQLP962TX3Hr",
      "authorship_tag": "ABX9TyP427ozuVDqTqwgVhqODcq0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dizzySummer/NLP-TensorFlow2.0/blob/master/Roberta.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cIo76z931l5U",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uYtVqmr40gah",
        "colab_type": "text"
      },
      "source": [
        "This is a test to combine a custom tokenization method (own corpus) with the Roberta model.  The corpus was chosen from twitter text.   No text preprocessing needed. TPU is required."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "prrFtCX81W1O",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "42c5eaaf-e6ae-4962-ddba-b300ffa1a75b"
      },
      "source": [
        "!import libraries and data"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/bin/bash: import: command not found\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qPFr880Hn4Vh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#!pip install transformers"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3PvZv7hZoNON",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e96cd7a9-d4de-47b1-8697-149ff085038e"
      },
      "source": [
        "%tensorflow_version 2.x"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 2.x selected.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oJ42oDHunf_j",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "f7b8793a-acf1-4995-f488-65e1ba834711"
      },
      "source": [
        "import numpy as np \n",
        "import pandas as pd \n",
        "from tensorflow.keras.layers import Dense, Input\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "import tensorflow_hub as hub\n",
        "\n",
        "import os\n",
        "import time\n",
        "import sys\n",
        "\n",
        "import re\n",
        "import nltk \n",
        "nltk.download('punkt')\n",
        "from nltk.corpus import stopwords\n",
        "import tensorflow as tf\n",
        "tf.keras.backend.clear_session()\n",
        "\n",
        "import torch\n",
        "import transformers\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from transformers import *\n",
        "from transformers import RobertaConfig, TFRobertaPreTrainedModel\n",
        "from transformers.modeling_tf_roberta import TFRobertaMainLayer\n",
        "from transformers.modeling_tf_utils import get_initializer\n",
        "\n",
        "import itertools\n",
        "import collections\n",
        "from collections import Counter\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F95TI_D6pTu9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "b39c0573-cb0a-4de3-dbf6-644974803d1e"
      },
      "source": [
        "#turn on TPU https://heartbeat.fritz.ai/step-by-step-use-of-google-colab-free-tpu-75f8629492b3\n",
        "resolver = tf.distribute.cluster_resolver.TPUClusterResolver()\n",
        "tf.config.experimental_connect_to_cluster(resolver)\n",
        "tf.tpu.experimental.initialize_tpu_system(resolver)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:absl:Entering into master device scope: /job:worker/replica:0/task:0/device:CPU:0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: 10.103.80.154:8470\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: 10.103.80.154:8470\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.tpu.topology.Topology at 0x7f27b811ec18>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VNzl7RyPpZZN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train = pd.read_csv(\"/content/drive/My Drive/train.csv\")\n",
        "test = pd.read_csv(\"/content/drive/My Drive/test.csv\")\n",
        "submission=pd.read_csv(\"/content/drive/My Drive/sample_submission.csv\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eM7YseO3555z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "330a1559-769d-4603-c6de-fa5c3ca4a9bf"
      },
      "source": [
        "test.head()"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>keyword</th>\n",
              "      <th>location</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Just happened a terrible car crash</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Heard about #earthquake is different cities, s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>there is a forest fire at spot pond, geese are...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>9</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Apocalypse lighting. #Spokane #wildfires</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>11</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Typhoon Soudelor kills 28 in China and Taiwan</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id keyword location                                               text\n",
              "0   0     NaN      NaN                 Just happened a terrible car crash\n",
              "1   2     NaN      NaN  Heard about #earthquake is different cities, s...\n",
              "2   3     NaN      NaN  there is a forest fire at spot pond, geese are...\n",
              "3   9     NaN      NaN           Apocalypse lighting. #Spokane #wildfires\n",
              "4  11     NaN      NaN      Typhoon Soudelor kills 28 in China and Taiwan"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c7U8s7Tk58ca",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "fce6f599-b394-448b-e8eb-d479a4156195"
      },
      "source": [
        "train.head()"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>keyword</th>\n",
              "      <th>location</th>\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "      <th>Tokened_Text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
              "      <td>1</td>\n",
              "      <td>[2, 690, 12134, 257, 143, 2635, 157, 251, 6, 1...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
              "      <td>1</td>\n",
              "      <td>[2, 987, 337, 672, 1312, 5587, 473, 361, 89, 9...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>All residents asked to 'shelter in place' are ...</td>\n",
              "      <td>1</td>\n",
              "      <td>[2, 319, 4995, 4568, 153, 10, 5241, 149, 2204,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>6</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
              "      <td>1</td>\n",
              "      <td>[2, 1360, 15, 7036, 438, 14629, 6, 4237, 1261,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>7</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
              "      <td>1</td>\n",
              "      <td>[2, 299, 636, 2596, 251, 1439, 272, 1479, 102,...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id keyword  ... target                                       Tokened_Text\n",
              "0   1     NaN  ...      1  [2, 690, 12134, 257, 143, 2635, 157, 251, 6, 1...\n",
              "1   4     NaN  ...      1  [2, 987, 337, 672, 1312, 5587, 473, 361, 89, 9...\n",
              "2   5     NaN  ...      1  [2, 319, 4995, 4568, 153, 10, 5241, 149, 2204,...\n",
              "3   6     NaN  ...      1  [2, 1360, 15, 7036, 438, 14629, 6, 4237, 1261,...\n",
              "4   7     NaN  ...      1  [2, 299, 636, 2596, 251, 1439, 272, 1479, 102,...\n",
              "\n",
              "[5 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mwzeDCK8p633",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "ba1f631e-c897-470d-fa3e-665769787ff1"
      },
      "source": [
        "# check class distribution in train dataset\n",
        "from scipy import stats\n",
        "train.groupby(['target']).size()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "target\n",
              "0    4342\n",
              "1    3271\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l8XxmgHx3ATZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Build corpus"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pWGouAYrqATI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "all_texts = []\n",
        "for line in list(train['text']):\n",
        "    texts = line.split()\n",
        "    for text in texts:\n",
        "        all_texts.append(text)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tBoDcDjVqDxk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "toBeCleanedNew='[%s]' % ' '.join(map(str, all_texts))#remove all the quation marks and commas. \n",
        "#print(toBeCleanedNew)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ap1i831MqJDG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "rawCorpus='[%s]' % ' '.join(map(str, all_texts))#remove all the quation marks and commas. \n",
        "#print(rawCorpus)\n",
        "with open(\"/content/drive/My Drive/rawCorpus.txt\", \"w\") as output:\n",
        "    output.write(str(rawCorpus))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dQgcIs0n3DkB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#install transformer tokenizers to train corpus"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ri7S69475QsD",
        "colab_type": "text"
      },
      "source": [
        "Here are the pre-process requirement for the 5 model types recommended by  huggingface. \n",
        "\n",
        "BERT: [CLS] + tokens + [SEP] + padding\n",
        "\n",
        "DistilBERT: [CLS] + tokens + [SEP] + padding\n",
        "\n",
        "RoBERTa: [CLS] + prefix_space + tokens + [SEP] + padding\n",
        "\n",
        "XLM: [CLS] + tokens + [SEP] + padding\n",
        "\n",
        "XLNet: padding + tokens + [SEP] + [CLS]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "873DykUaqQZA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "46990ece-4d08-4521-cb51-be0d3e7b9554"
      },
      "source": [
        "!pip install tokenizers==0.4.2"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tokenizers==0.4.2 in /usr/local/lib/python3.6/dist-packages (0.4.2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QY2OiS5EuvUS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#!pip install tokenizers #hugging face tokenizer\n",
        "#Huggingface recommends to use ByteLevel tokenizer for Roberta model. But the result was bad. Take BertWordPiece now\n",
        "from tokenizers import (ByteLevelBPETokenizer,\n",
        "                            CharBPETokenizer,\n",
        "                            SentencePieceBPETokenizer,\n",
        "                            BertWordPieceTokenizer)\n",
        "tokenizer = BertWordPieceTokenizer()\n",
        "\n",
        "path=\"/content/drive/My Drive/rawCorpus.txt\"\n",
        "#set vocab_size to 15000 as the len(train_set)was something like 12500 \n",
        "tokenizer.train(files=path, vocab_size=15_000, min_frequency=2)\n",
        "#tokenizer.train(files=path, vocab_size=15_000, min_frequency=2,special_tokens=[\n",
        "   # \"<s>\",\n",
        "    #\"<pad>\",\n",
        "    #\"</s>\",\n",
        "    #\"<unk>\",\n",
        "    #\"<mask>\"\n",
        "#])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F_cpxcBsvD73",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "372710f9-6fee-4033-9e1a-3edcaa36dfd4"
      },
      "source": [
        "tokenizer.save(\".\",\"/content/drive/My Drive/newBert\")"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['/content/drive/My Drive/newBert-vocab.txt']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gVYKQZPvqmix",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tokenizer = BertWordPieceTokenizer(\n",
        "    '/content/drive/My Drive/newBert-vocab.txt',\n",
        "     lowercase=True, \n",
        "\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bC_3lqc4wRZE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "6948be03-8877-4e0e-ca7e-170cf6f28e85"
      },
      "source": [
        "output = tokenizer.encode(\"Hello, y'all! 🙂 How are you  ?\")\n",
        "print(output.tokens)\n",
        "print(output.ids)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['[CLS]', 'hello', ',', 'y', \"'\", 'all', '!', '[UNK]', 'how', 'are', 'you', '?', '[SEP]']\n",
            "[2, 3996, 15, 65, 10, 319, 5, 1, 439, 257, 172, 33, 3]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "srLPPOjb3LPU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#apply tokens to all texts"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gh2P9mTaqwog",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def bert_token(texts,max_len=512): \n",
        "    all_input_ids=[]\n",
        "    all_mask_ids=[]\n",
        "    all_seg_ids=[]\n",
        "    for token in texts: \n",
        "    \n",
        "        input_ids=tokenizer.encode(token).ids\n",
        "        mask_ids = [1] * len(input_ids)\n",
        "        seg_ids = [0] * len(input_ids)\n",
        "        padding = [0] * (max_len - len(input_ids))\n",
        "        input_ids += padding\n",
        "        mask_ids += padding\n",
        "        seg_ids += padding\n",
        "        all_input_ids.append(input_ids)\n",
        "        all_mask_ids.append(mask_ids)\n",
        "        all_seg_ids.append(seg_ids)\n",
        "\n",
        "    \n",
        "    return np.array(all_input_ids), np.array(all_mask_ids), np.array(all_seg_ids)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n30FQPu6q1ca",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_input=bert_token(train['text'],max_len=100)\n",
        "test_input=bert_token(test['text'],max_len=100)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P-3CiuGOvg1d",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        },
        "outputId": "641b6a20-231e-46b8-a715-640c5319ad66"
      },
      "source": [
        "print(train_input)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(array([[    2,   690, 12134, ...,     0,     0,     0],\n",
            "       [    2,   987,   337, ...,     0,     0,     0],\n",
            "       [    2,   319,  4995, ...,     0,     0,     0],\n",
            "       ...,\n",
            "       [    2,  5086,    17, ...,     0,     0,     0],\n",
            "       [    2,   537,  3264, ...,     0,     0,     0],\n",
            "       [    2,   143,  1043, ...,     0,     0,     0]]), array([[1, 1, 1, ..., 0, 0, 0],\n",
            "       [1, 1, 1, ..., 0, 0, 0],\n",
            "       [1, 1, 1, ..., 0, 0, 0],\n",
            "       ...,\n",
            "       [1, 1, 1, ..., 0, 0, 0],\n",
            "       [1, 1, 1, ..., 0, 0, 0],\n",
            "       [1, 1, 1, ..., 0, 0, 0]]), array([[0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       ...,\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0]]))\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0FLcGbHb3RyO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#take a quick look of the trainset"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sTcn4sxNyQl0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "6ffa6fa9-ab34-4412-b878-5860e36d0a2d"
      },
      "source": [
        "train[\"Tokened_Text\"]=train[\"text\"].apply(lambda x:tokenizer.encode(x).ids)\n",
        "from collections import Counter\n",
        "train_tokened=[]\n",
        "for i in train[\"Tokened_Text\"]:\n",
        "    train_tokened+=i\n",
        "print(\"Total amount of tokens in train dataset is:\", len(train_tokened))\n",
        "distinct_list= (Counter(train_tokened).keys())\n",
        "print(\"The vocabulary size in subtrain dataset is :\",len(distinct_list))"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total amount of tokens in train dataset is: 232945\n",
            "The vocabulary size in subtrain dataset is : 13393\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q4FH6Bgsq5PO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "0aa23a0f-3bf2-442a-bf75-93a44caa02e2"
      },
      "source": [
        "#sequence length of the train dataset\n",
        "train_length_dist=[]\n",
        "\n",
        "for l in train[\"Tokened_Text\"]:\n",
        "    train_length_dist+=[len(l)]\n",
        "y = np.array(train_length_dist)\n",
        "sns.distplot(y);"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD4CAYAAADiry33AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\niXL/HxIUSUSXTrWsAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0uxLKPrtrAYl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Model need two types of data: input_ids (sequence), attention_masks)\n",
        "input_ids_train = train_input[0]\n",
        "attention_masks_train = train_input[1]\n",
        "input_ids_test =test_input[0]\n",
        "attention_masks_test = test_input[1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n51MDoltrHdJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "db102a82-5c6d-4153-cd31-7f92ae5d48e5"
      },
      "source": [
        "print(input_ids_train)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[    2   690 12134 ...     0     0     0]\n",
            " [    2   987   337 ...     0     0     0]\n",
            " [    2   319  4995 ...     0     0     0]\n",
            " ...\n",
            " [    2  5086    17 ...     0     0     0]\n",
            " [    2   537  3264 ...     0     0     0]\n",
            " [    2   143  1043 ...     0     0     0]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WwaV_yE13tcq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Build a cover on top of hugging face pretrained model. Here is another example https://towardsdatascience.com/fastai-with-transformers-bert-roberta-xlnet-xlm-distilbert-4f41ee18ecb2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W4Snmo8Us0St",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class CustomModel(TFRobertaPreTrainedModel):\n",
        "    def __init__(self, config, *inputs, **kwargs):\n",
        "        super(CustomModel, self).__init__(config, *inputs, **kwargs)\n",
        "        self.num_labels = config.num_labels\n",
        "        self.roberta = TFRobertaMainLayer(config, name=\"roberta\")\n",
        "        self.dropout_1 = tf.keras.layers.Dropout(0.3)\n",
        "        self.classifier = tf.keras.layers.Dense(units=config.num_labels,\n",
        "                                                name='classifier', \n",
        "                                                kernel_initializer=get_initializer(\n",
        "                                                    config.initializer_range))\n",
        "\n",
        "    def call(self, inputs, **kwargs):\n",
        "        outputs = self.roberta(inputs, **kwargs)\n",
        "        pooled_output = outputs[1]\n",
        "        pooled_output = self.dropout_1(pooled_output, training=kwargs.get('training', False))\n",
        "        logits = self.classifier(pooled_output)\n",
        "        outputs = (logits,) + outputs[2:]  # add hidden states and attention if they are here\n",
        "\n",
        "        return outputs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j9B6BP9It3V-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 833
        },
        "outputId": "6d1d4128-3e91-4f7e-dc92-a6c8a2621470"
      },
      "source": [
        "# instantiate a distribution strategy\n",
        "tpu_strategy = tf.distribute.experimental.TPUStrategy(resolver)\n",
        "\n",
        "\n",
        "# instantiating the model in the strategy scope creates the model on the TPU\n",
        "with tpu_strategy.scope():\n",
        "        \n",
        "    config = RobertaConfig.from_pretrained('roberta-base')\n",
        "    model = CustomModel.from_pretrained('roberta-base')\n",
        "    optimizer = tf.keras.optimizers.Adam(learning_rate=2e-5, epsilon=1e-08, clipnorm=1.0)\n",
        "    loss = tf.keras.losses.CategoricalCrossentropy(from_logits=True)\n",
        "    metric = tf.keras.metrics.BinaryAccuracy('accuracy')\n",
        "    model.compile(optimizer=optimizer, loss=loss, metrics=[metric])\n",
        "model.summary()\n"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Found TPU system:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Found TPU system:\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores: 8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores: 8\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Workers: 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Workers: 1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model: \"custom_model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "roberta (TFRobertaMainLayer) multiple                  124645632 \n",
            "_________________________________________________________________\n",
            "dropout_38 (Dropout)         multiple                  0         \n",
            "_________________________________________________________________\n",
            "classifier (Dense)           multiple                  1538      \n",
            "=================================================================\n",
            "Total params: 124,647,170\n",
            "Trainable params: 124,647,170\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yukSWJbpt7Xj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "757a1e36-7222-4ddb-f10f-ffc5343c821f"
      },
      "source": [
        "batch_size = 128\n",
        "skf = StratifiedKFold(n_splits=5, shuffle=False)\n",
        "X, y = input_ids_train, train['target'].values.reshape(-1, 1)\n",
        "skf.get_n_splits(X, y)\n",
        "for i, (train_index, test_index) in enumerate(skf.split(X, y)):\n",
        "    X_train, attention_masks_train_stratified, X_test, attention_masks_test_stratified = X[train_index], attention_masks_train[train_index], X[test_index], attention_masks_train[test_index]\n",
        "    y_train, y_test = tf.keras.utils.to_categorical(y[train_index]), tf.keras.utils.to_categorical(y[test_index])\n",
        "    X_train = X_train[:-divmod(X_train.shape[0], batch_size)[1]]\n",
        "    attention_masks_train_stratified = attention_masks_train_stratified[:-divmod(attention_masks_train_stratified.shape[0], batch_size)[1]]\n",
        "    y_train = y_train[:-divmod(y_train.shape[0], batch_size)[1]]\n",
        "    model.fit([X_train, attention_masks_train_stratified], y_train, validation_data=([X_test, attention_masks_test_stratified], y_test), batch_size=batch_size, epochs=5)\n",
        "    print('Split ' + str(i) + ' is finished.')"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 6016 samples, validate on 1523 samples\n",
            "Epoch 1/5\n",
            "6016/6016 [==============================] - 86s 14ms/sample - loss: 0.6580 - accuracy: 0.5230 - val_loss: 0.6750 - val_accuracy: 0.5794\n",
            "Epoch 2/5\n",
            "6016/6016 [==============================] - 8s 1ms/sample - loss: 0.6200 - accuracy: 0.5673 - val_loss: 0.6261 - val_accuracy: 0.5814\n",
            "Epoch 3/5\n",
            "6016/6016 [==============================] - 7s 1ms/sample - loss: 0.5641 - accuracy: 0.6198 - val_loss: 0.6184 - val_accuracy: 0.5532\n",
            "Epoch 4/5\n",
            "6016/6016 [==============================] - 8s 1ms/sample - loss: 0.4893 - accuracy: 0.6820 - val_loss: 0.6386 - val_accuracy: 0.6504\n",
            "Epoch 5/5\n",
            "6016/6016 [==============================] - 8s 1ms/sample - loss: 0.4124 - accuracy: 0.7657 - val_loss: 0.7497 - val_accuracy: 0.6737\n",
            "Split 0 is finished.\n",
            "Train on 6016 samples, validate on 1523 samples\n",
            "Epoch 1/5\n",
            "6016/6016 [==============================] - 29s 5ms/sample - loss: 0.4380 - accuracy: 0.7565 - val_loss: 0.2383 - val_accuracy: 0.8835\n",
            "Epoch 2/5\n",
            "6016/6016 [==============================] - 8s 1ms/sample - loss: 0.3469 - accuracy: 0.8206 - val_loss: 0.2481 - val_accuracy: 0.8838\n",
            "Epoch 3/5\n",
            "6016/6016 [==============================] - 8s 1ms/sample - loss: 0.2800 - accuracy: 0.8605 - val_loss: 0.2493 - val_accuracy: 0.8851\n",
            "Epoch 4/5\n",
            "6016/6016 [==============================] - 8s 1ms/sample - loss: 0.2388 - accuracy: 0.8868 - val_loss: 0.3383 - val_accuracy: 0.8404\n",
            "Epoch 5/5\n",
            "6016/6016 [==============================] - 8s 1ms/sample - loss: 0.1886 - accuracy: 0.9148 - val_loss: 0.4156 - val_accuracy: 0.8276\n",
            "Split 1 is finished.\n",
            "Train on 6016 samples, validate on 1523 samples\n",
            "Epoch 1/5\n",
            "6016/6016 [==============================] - 28s 5ms/sample - loss: 0.2305 - accuracy: 0.8934 - val_loss: 0.0650 - val_accuracy: 0.9770\n",
            "Epoch 2/5\n",
            "6016/6016 [==============================] - 8s 1ms/sample - loss: 0.1605 - accuracy: 0.9288 - val_loss: 0.0804 - val_accuracy: 0.9698\n",
            "Epoch 3/5\n",
            "6016/6016 [==============================] - 8s 1ms/sample - loss: 0.1519 - accuracy: 0.9323 - val_loss: 0.0901 - val_accuracy: 0.9583\n",
            "Epoch 4/5\n",
            "6016/6016 [==============================] - 8s 1ms/sample - loss: 0.1025 - accuracy: 0.9533 - val_loss: 0.0770 - val_accuracy: 0.9724\n",
            "Epoch 5/5\n",
            "6016/6016 [==============================] - 8s 1ms/sample - loss: 0.1074 - accuracy: 0.9541 - val_loss: 0.1081 - val_accuracy: 0.9596\n",
            "Split 2 is finished.\n",
            "Train on 6016 samples, validate on 1522 samples\n",
            "Epoch 1/5\n",
            "6016/6016 [==============================] - 28s 5ms/sample - loss: 0.1052 - accuracy: 0.9556 - val_loss: 0.0174 - val_accuracy: 0.9921\n",
            "Epoch 2/5\n",
            "6016/6016 [==============================] - 8s 1ms/sample - loss: 0.0814 - accuracy: 0.9669 - val_loss: 0.0183 - val_accuracy: 0.9915\n",
            "Epoch 3/5\n",
            "6016/6016 [==============================] - 8s 1ms/sample - loss: 0.0615 - accuracy: 0.9734 - val_loss: 0.0254 - val_accuracy: 0.9938\n",
            "Epoch 4/5\n",
            "6016/6016 [==============================] - 8s 1ms/sample - loss: 0.0719 - accuracy: 0.9706 - val_loss: 0.0262 - val_accuracy: 0.9918\n",
            "Epoch 5/5\n",
            "6016/6016 [==============================] - 8s 1ms/sample - loss: 0.0634 - accuracy: 0.9754 - val_loss: 0.0331 - val_accuracy: 0.9885\n",
            "Split 3 is finished.\n",
            "Train on 6016 samples, validate on 1522 samples\n",
            "Epoch 1/5\n",
            "6016/6016 [==============================] - 28s 5ms/sample - loss: 0.0663 - accuracy: 0.9710 - val_loss: 0.0359 - val_accuracy: 0.9921\n",
            "Epoch 2/5\n",
            "6016/6016 [==============================] - 8s 1ms/sample - loss: 0.0788 - accuracy: 0.9666 - val_loss: 0.0261 - val_accuracy: 0.9931\n",
            "Epoch 3/5\n",
            "6016/6016 [==============================] - 8s 1ms/sample - loss: 0.0487 - accuracy: 0.9806 - val_loss: 0.0456 - val_accuracy: 0.9882\n",
            "Epoch 4/5\n",
            "6016/6016 [==============================] - 8s 1ms/sample - loss: 0.0387 - accuracy: 0.9824 - val_loss: 0.0386 - val_accuracy: 0.9905\n",
            "Epoch 5/5\n",
            "6016/6016 [==============================] - 8s 1ms/sample - loss: 0.0417 - accuracy: 0.9839 - val_loss: 0.0453 - val_accuracy: 0.9878\n",
            "Split 4 is finished.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ziF0LkP4ONw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "7d106f22-0825-499c-c4b5-5b8401eb8df0"
      },
      "source": [
        "#predict\n",
        "\n",
        "model_output = model.predict([input_ids_test, attention_masks_test])\n",
        "submission['target'] = np.argmax(model_output, axis=1).flatten()\n",
        "submission['target'].value_counts()"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    1779\n",
              "1    1484\n",
              "Name: target, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XCtK9Ipv4g2q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "058f557d-c978-4a9b-ec60-19f483e1368b"
      },
      "source": [
        "submission.head()"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>9</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>11</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id  target\n",
              "0   0       1\n",
              "1   2       1\n",
              "2   3       1\n",
              "3   9       1\n",
              "4  11       1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    }
  ]
}