{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.0-beta1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "import tensorflow_datasets as tfds\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "imdb, info=tfds.load(\"imdb_reviews/subwords8k\", with_info=True, as_supervised=True)\n",
    "tokenizer=info.features['text'].encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_string='TensorFlow, flow basics to mastery'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenized string is [6307, 2327, 4043, 2120, 2, 2934, 7961, 4249, 4429, 7, 2652, 8050]\n"
     ]
    }
   ],
   "source": [
    "tokenized_string=tokenizer.encode(sample_string)\n",
    "print('Tokenized string is {}'. format(tokenized_string))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The original string: TensorFlow, flow basics to mastery\n"
     ]
    }
   ],
   "source": [
    "original_string=tokenizer.decode(tokenized_string)\n",
    "print('The original string: {}'.format(original_string))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6307--->Ten\n",
      "2327--->sor\n",
      "4043--->Fl\n",
      "2120--->ow\n",
      "2--->, \n",
      "2934--->flow\n",
      "7961---> \n",
      "4249--->basi\n",
      "4429--->cs \n",
      "7--->to \n",
      "2652--->master\n",
      "8050--->y\n"
     ]
    }
   ],
   "source": [
    "for ts in tokenized_string:\n",
    "    print('{}--->{}'.format(ts,tokenizer.decode([ts])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tensor=6307+2327, flow=4043+2120, basics=4249+4429"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
